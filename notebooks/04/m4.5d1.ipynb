{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Linear regression"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We estimate simple linear regression model with a half-T prior.\n",
    "First, we load the packages we use."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using StatisticalRethinking\n",
    "using DynamicHMC, TransformVariables, LogDensityProblems, MCMCDiagnostics\n",
    "using Parameters, ForwardDiff\n",
    "\n",
    "ProjDir = rel_path(\"..\", \"scripts\", \"04\")\n",
    "cd(ProjDir)"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Import the dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "howell1 = CSV.read(rel_path(\"..\", \"data\", \"Howell1.csv\"), delim=';')\n",
    "df = convert(DataFrame, howell1);"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Use only adults and standardize"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df2 = filter(row -> row[:age] >= 18, df)\n",
    "df2[:weight] = convert(Vector{Float64}, df2[:weight]);\n",
    "df2[:weight_s] = (df2[:weight] .- mean(df2[:weight])) / std(df2[:weight]);\n",
    "df2[:weight_s2] = df2[:weight_s] .^ 2;"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Show the first six rows of the dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6×6 DataFrame\n│ Row │ height   │ weight  │ age      │ male   │ weight_s  │ weight_s2 │\n│     │ \u001b[90mFloat64⍰\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │\n├─────┼──────────┼─────────┼──────────┼────────┼───────────┼───────────┤\n│ 1   │ 151.765  │ 47.8256 │ 63.0     │ 1      │ 0.439097  │ 0.192806  │\n│ 2   │ 139.7    │ 36.4858 │ 63.0     │ 0      │ -1.31718  │ 1.73498   │\n│ 3   │ 136.525  │ 31.8648 │ 65.0     │ 0      │ -2.03287  │ 4.13256   │\n│ 4   │ 156.845  │ 53.0419 │ 41.0     │ 1      │ 1.24699   │ 1.55498   │\n│ 5   │ 145.415  │ 41.2769 │ 51.0     │ 0      │ -0.575156 │ 0.330804  │\n│ 6   │ 163.83   │ 62.9926 │ 35.0     │ 1      │ 2.78812   │ 7.77364   │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>height</th><th>weight</th><th>age</th><th>male</th><th>weight_s</th><th>weight_s2</th></tr><tr><th></th><th>Float64⍰</th><th>Float64</th><th>Float64⍰</th><th>Int64⍰</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>6 rows × 6 columns</p><tr><th>1</th><td>151.765</td><td>47.8256</td><td>63.0</td><td>1</td><td>0.439097</td><td>0.192806</td></tr><tr><th>2</th><td>139.7</td><td>36.4858</td><td>63.0</td><td>0</td><td>-1.31718</td><td>1.73498</td></tr><tr><th>3</th><td>136.525</td><td>31.8648</td><td>65.0</td><td>0</td><td>-2.03287</td><td>4.13256</td></tr><tr><th>4</th><td>156.845</td><td>53.0419</td><td>41.0</td><td>1</td><td>1.24699</td><td>1.55498</td></tr><tr><th>5</th><td>145.415</td><td>41.2769</td><td>51.0</td><td>0</td><td>-0.575156</td><td>0.330804</td></tr><tr><th>6</th><td>163.83</td><td>62.9926</td><td>35.0</td><td>1</td><td>2.78812</td><td>7.77364</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "first(df2, 6)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Then define a structure to hold the data: observables, covariates, and the degrees of freedom for the prior."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Main.##425.LinearRegressionProblem"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Linear regression model ``y ∼ Xβ + ϵ``, where ``ϵ ∼ N(0, σ²)`` IID.\n",
    "Flat prior for `β`, half-T for `σ`.\n",
    "\"\"\"\n",
    "struct LinearRegressionProblem{TY <: AbstractVector, TX <: AbstractMatrix,\n",
    "Tν <: Real}\n",
    "    \"Observations.\"\n",
    "    y::TY\n",
    "    \"Covariates\"\n",
    "    X::TX\n",
    "    \"Degrees of freedom for prior.\"\n",
    "    ν::Tν\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Then make the type callable with the parameters *as a single argument*."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function (problem::LinearRegressionProblem)(θ)\n",
    "    @unpack y, X, ν = problem   # extract the data\n",
    "    @unpack β, σ = θ            # works on the named tuple too\n",
    "    loglikelihood(Normal(0, σ), y .- X*β) + logpdf(TDist(ν), σ)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We should test this, also, this would be a good place to benchmark and\n",
    "optimize more complicated problems."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-4.001310714028722e6"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "N = size(df2, 1)\n",
    "X = hcat(ones(N), hcat(df2[:weight_s], df2[:weight_s2]));\n",
    "y = convert(Vector{Float64}, df2[:height])\n",
    "p = LinearRegressionProblem(y, X, 1.0);\n",
    "p((β = [1.0, 2.0, 3.0], σ = 1.0))"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "For this problem, we write a function to return the transformation (as it varies with the number of covariates)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "problem_transformation(p::LinearRegressionProblem) =\n",
    "    as((β = as(Array, size(p.X, 2)), σ = asℝ₊))\n",
    "# Wrap the problem with a transformation, then use Flux for the gradient.\n",
    "P = TransformedLogDensity(problem_transformation(p), p)\n",
    "∇P = ADgradient(:ForwardDiff, P);"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Finally, we sample from the posterior. `chain` holds the chain (positions and\n",
    "diagnostic information), while the second returned value is the tuned sampler\n",
    "which would allow continuation of sampling."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMC, adapting ϵ (75 steps)\n",
      "0.0022 s/step ...done\n",
      "MCMC, adapting ϵ (25 steps)\n",
      "0.00066 s/step ...done\n",
      "MCMC, adapting ϵ (50 steps)\n",
      "0.0027 s/step ...done\n",
      "MCMC, adapting ϵ (100 steps)\n",
      "0.00037 s/step ...done\n",
      "MCMC, adapting ϵ (200 steps)\n",
      "0.00022 s/step ...done\n",
      "MCMC, adapting ϵ (400 steps)\n",
      "0.00018 s/step ...done\n",
      "MCMC, adapting ϵ (50 steps)\n",
      "0.00029 s/step ...done\n",
      "MCMC (1000 steps)\n",
      "0.00024 s/step ...done\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "chain, NUTS_tuned = NUTS_init_tune_mcmc(∇P, 1000);"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We use the transformation to obtain the posterior from the chain."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5-element Array{NamedTuple{(:β, :σ),Tuple{Array{Float64,1},Float64}},1}:\n (β = [154.56, 6.45256, 0.148852], σ = 5.28369403566664)    \n (β = [154.496, 6.29349, -0.115618], σ = 5.172425987181745) \n (β = [154.551, 5.5715, 0.0632081], σ = 4.993268526160111)  \n (β = [154.494, 5.70218, -0.10765], σ = 4.819265182603345)  \n (β = [155.021, 5.89168, -0.248484], σ = 5.0462605183232565)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "posterior = TransformVariables.transform.(Ref(∇P.transformation), get_position.(chain));\n",
    "posterior[1:5]"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Extract the parameter posterior means: `β`,"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3-element Array{Float64,1}:\n 154.6258765668        \n   5.847670335408231   \n  -0.013126210660355265"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "posterior_β = mean(first, posterior)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "then `σ`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5.1079280677558145"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "posterior_σ = mean(last, posterior)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Effective sample sizes (of untransformed draws)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ess = mapslices(effective_sample_size,\n",
    "                get_position_matrix(chain); dims = 1)\n",
    "# NUTS-specific statistics\n",
    "NUTS_statistics(chain)\n",
    "\n",
    "cmdstan_result = \"\n",
    "Iterations = 1:1000\n",
    "Thinning interval = 1\n",
    "Chains = 1,2,3,4\n",
    "Samples per chain = 1000\n",
    "\n",
    "Empirical Posterior Estimates:\n",
    "           Mean         SD       Naive SE       MCSE      ESS\n",
    "    a 154.609019750 0.36158389 0.0057171433 0.0071845548 1000\n",
    "   b1   5.838431778 0.27920926 0.0044146860 0.0048693502 1000\n",
    "   b2  -0.009985954 0.22897191 0.0036203637 0.0047224478 1000\n",
    "sigma   5.110136300 0.19096315 0.0030193925 0.0030728192 1000\n",
    "\n",
    "Quantiles:\n",
    "          2.5%        25.0%        50.0%       75.0%        97.5%\n",
    "    a 153.92392500 154.3567500 154.60700000 154.8502500 155.32100000\n",
    "   b1   5.27846200   5.6493250   5.83991000   6.0276275   6.39728200\n",
    "   b2  -0.45954687  -0.1668285  -0.01382935   0.1423620   0.43600905\n",
    "sigma   4.76114350   4.9816850   5.10326000   5.2300450   5.51500975\n",
    "\";"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Extract the parameter posterior means: `β`,"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element Array{Any,1}:\n  [154.626, 5.84767, -0.0131262]\n 5.1079280677558145             "
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "[posterior_β, posterior_σ]"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "end of m4.5d.jl#-\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0-DEV.226"
  },
  "kernelspec": {
   "name": "julia-1.2",
   "display_name": "Julia 1.2.0-DEV.226",
   "language": "julia"
  }
 },
 "nbformat": 4
}
